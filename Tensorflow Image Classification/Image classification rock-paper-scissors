## First we import package 
import tensorflow as tf
import numpy as np
import zipfile, os
import shutil
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from google.colab import files
from tensorflow.keras import preprocessing
from tensorflow import keras
from tensorflow.keras import layers
from keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.applications.vgg16 import VGG16
from keras.applications.inception_v3 import InceptionV3
from sklearn.model_selection import train_test_split

## I try to install it in cmd, but it doesn't work, so i rewrite in here
!pip install split-folders
import splitfolders

## get folder
!wget --no-check-certificate \
  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip \
  -O /tmp/rockpaperscissors.zip
  
## extract folder
local_zip = '/tmp/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

## split folder with 60% train data and 40% test data
base_dir = '/tmp/rockpaperscissors/rps-cv-images'
splitfolders.ratio(base_dir, output='/tmp/rockpaperscissors',
    seed=1337, ratio=(.6, .4))
train_dir = os.path.join('/tmp/rockpaperscissors', 'train')
validation_dir = os.path.join('/tmp/rockpaperscissors', 'val')

rock_dir = os.path.join(base_dir, 'rock')
paper_dir = os.path.join(base_dir, 'paper')
scissors_dir = os.path.join(base_dir, 'scissors')

## use train_test_split
train_rock_dir, validation_rock_dir = train_test_split(os.listdir(rock_dir), test_size = 0.4)
train_paper_dir, validation_paper_dir = train_test_split(os.listdir(paper_dir), test_size = 0.4)
train_scissors_dir, validation_scissors_dir = train_test_split(os.listdir(scissors_dir), test_size = 0.4)

rock_train = os.path.join(train_dir, 'rock')
scissors_train = os.path.join(train_dir, 'scissors')
paper_train = os.path.join(train_dir, 'paper')
rock_validation = os.path.join(validation_dir, 'rock')
paper_validation = os.path.join(validation_dir, 'paper')
scissors_train = os.path.join(validation_dir, 'scissors')

## Image Data Generator
train_datagen = ImageDataGenerator (
    rescale = 1./255,
    rotation_range = 20,
    horizontal_flip = True,
    shear_range = 0.4,
    fill_mode = 'nearest'
)

test_datagen = ImageDataGenerator (
    rescale = 1./255,
    rotation_range = 20,
    horizontal_flip = True,
    shear_range = 0.4,
    fill_mode = 'nearest'
)

## train and validation generator
train_generator = train_datagen.flow_from_directory(
    train_dir, 
    target_size = (150,150),
    batch_size = 32,
    class_mode = 'categorical'
)

validation_generator = test_datagen.flow_from_directory(
    validation_dir,
    target_size = (150,150),
    batch_size = 32,
    class_mode = 'categorical'
)

## in here i use 4 convolution layer and 1 dense layer with relu activation
model = tf.keras.models.Sequential ([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

## try model summary
model.summary()

## The method that I used is categorical_crossentropy for losses classes and RMSprop for the optimizer 
model.compile(loss='categorical_crossentropy', optimizer  = tf.optimizers.experimental.RMSprop(), metrics=['accuracy'])

## fit the model
model.fit(
    train_generator,
    steps_per_epoch = 25,
    epochs = 20,
    validation_data = validation_generator,
    validation_steps = 5,
    verbose = 2
)

## Final step
%matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():
  path = fn
  img = image.load_img(path, target_size=(150,150))

  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis = 0)
  images = np.vstack([x])

  classes = model.predict(images, batch_size=12)
  print(fn)
  if classes[0][0] == 1:
    print('Rock')
  elif classes[0][1] == 1:
    print('Paper')
  elif classes[0][2] == 1:
    print('Scissors')
    

##------------------NOTE------------------##
Honestly, this code can not predict 100%. I'm still confused about why this is happening, even though the accuracy is above 80%. 
Another thing that confuses me is if I add a new dense layer. 
As a result, the accuracy is reduced, and I have to change the pixels of the image so that the accuracy is high.
